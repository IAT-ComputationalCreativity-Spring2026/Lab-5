{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8dN2z71g_3E"
      },
      "source": [
        "# Multi-Agent Creative Systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "To0WvKAkg_3F"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXg3XsiIg_3G",
        "outputId": "4dd72fea-f705-46b7-9b0a-49d56d3594ae"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q langchain langchain-core torch\n",
        "!pip install -q pydantic pronouncing nltk\n",
        "!pip install -U \"langchain[google-genai]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJInl6kWg_3H",
        "outputId": "b21a56be-8d70-43a1-b488-69112d8c09a4"
      },
      "outputs": [],
      "source": [
        "# Core imports\n",
        "import os\n",
        "from typing import TypedDict, List, Optional, Any, Dict, Literal\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# LangChain imports\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.messages import HumanMessage, SystemMessage, AIMessage\n",
        "from langchain.agents import create_agent\n",
        "from langchain.tools import tool\n",
        "from langchain.agents import (\n",
        "    create_agent,\n",
        "    AgentState,\n",
        ")\n",
        "from langchain.agents.middleware import (\n",
        "    AgentMiddleware,\n",
        "    ModelRequest,\n",
        "    ModelResponse,\n",
        "    ToolCallRequest,\n",
        "    dynamic_prompt,\n",
        "    wrap_model_call,\n",
        "    wrap_tool_call,\n",
        "    before_model,\n",
        "    after_model\n",
        ")\n",
        "from langchain.agents.structured_output import ToolStrategy, ProviderStrategy\n",
        "\n",
        "# Utilities\n",
        "import pronouncing\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"All libraries imported successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT0soh0qg_3H"
      },
      "source": [
        "## Initialize Gemini API model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dggZdonHqOws"
      },
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "\n",
        "# Set environment variables\n",
        "os.environ['GOOGLE_API_KEY'] = getpass('Enter your Google API key: ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrKnzukfg_3H",
        "outputId": "3a18dd9e-2ea2-4491-c2d8-820ba6a4ec3d"
      },
      "outputs": [],
      "source": [
        "base_llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite\")\n",
        "\n",
        "print(\"Model endpoint ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QP4mqTqzg_3I"
      },
      "source": [
        "## Define tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCqOPcaAg_3I",
        "outputId": "dc038e77-8aa5-48c5-959f-425c7ef7fe17"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def find_rhymes(word: str) -> str:\n",
        "    \"\"\"Find rhyming words for creative writing. Returns comma-separated list of rhymes.\n",
        "\n",
        "    Args:\n",
        "        word: The word to find rhymes for\n",
        "\n",
        "    Returns:\n",
        "        A comma-separated list of rhyming words\n",
        "    \"\"\"\n",
        "    word = word.strip().lower()\n",
        "    rhymes = pronouncing.rhymes(word)\n",
        "\n",
        "    if not rhymes:\n",
        "        return f\"No rhymes found for '{word}'\"\n",
        "\n",
        "    # Return top 10 rhymes\n",
        "    top_rhymes = rhymes[:10]\n",
        "    return \", \".join(top_rhymes)\n",
        "\n",
        "\n",
        "@tool\n",
        "def count_syllables(text: str) -> str:\n",
        "    \"\"\"Count syllables in a word or phrase for poetry and rhythm analysis.\n",
        "\n",
        "    Args:\n",
        "        text: The word or phrase to analyze\n",
        "\n",
        "    Returns:\n",
        "        Total syllable count and breakdown by word\n",
        "    \"\"\"\n",
        "    text = text.strip().lower()\n",
        "    words = text.split()\n",
        "\n",
        "    total_syllables = 0\n",
        "    word_counts = []\n",
        "\n",
        "    for word in words:\n",
        "        # Remove punctuation\n",
        "        word = ''.join(c for c in word if c.isalnum())\n",
        "        phones = pronouncing.phones_for_word(word)\n",
        "\n",
        "        if phones:\n",
        "            syllable_count = pronouncing.syllable_count(phones[0])\n",
        "            total_syllables += syllable_count\n",
        "            word_counts.append(f\"{word}({syllable_count})\")\n",
        "        else:\n",
        "            # Estimate for unknown words\n",
        "            estimate = max(1, len([c for c in word if c in 'aeiou']))\n",
        "            total_syllables += estimate\n",
        "            word_counts.append(f\"{word}(~{estimate})\")\n",
        "\n",
        "    return f\"Total: {total_syllables} syllables. Breakdown: {' '.join(word_counts)}\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def analyze_meter(line: str) -> str:\n",
        "    \"\"\"Analyze the poetic meter of a line of text.\n",
        "\n",
        "    Args:\n",
        "        line: A line of poetry or dialogue to analyze\n",
        "\n",
        "    Returns:\n",
        "        Stress pattern and meter type\n",
        "    \"\"\"\n",
        "    words = line.strip().lower().split()\n",
        "    stresses = []\n",
        "\n",
        "    for word in words:\n",
        "        word = ''.join(c for c in word if c.isalnum())\n",
        "        phones = pronouncing.phones_for_word(word)\n",
        "\n",
        "        if phones:\n",
        "            stress = pronouncing.stresses(phones[0])\n",
        "            stresses.append(stress)\n",
        "\n",
        "    pattern = ''.join(stresses)\n",
        "\n",
        "    # Simple meter detection\n",
        "    if pattern.count('10') > 2:\n",
        "        meter = \"iambic (weak-strong)\"\n",
        "    elif pattern.count('01') > 2:\n",
        "        meter = \"trochaic (strong-weak)\"\n",
        "    else:\n",
        "        meter = \"mixed or free verse\"\n",
        "\n",
        "    return f\"Pattern: {pattern}. Meter: {meter}\"\n",
        "\n",
        "\n",
        "# List of all creative tools\n",
        "creative_tools = [find_rhymes, count_syllables, analyze_meter]\n",
        "\n",
        "print(\"âœ“ Tools defined:\")\n",
        "for tool_obj in creative_tools:\n",
        "    print(f\"  - {tool_obj.name}: {tool_obj.description[:60]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woEdLyAJrxCj"
      },
      "outputs": [],
      "source": [
        "from langchain.messages import ToolMessage\n",
        "\n",
        "@wrap_tool_call\n",
        "def handle_tool_errors(request, handler):\n",
        "    \"\"\"Handle tool execution errors with custom messages.\"\"\"\n",
        "    try:\n",
        "        return handler(request)\n",
        "    except Exception as e:\n",
        "        # Return a custom error message to the model\n",
        "        return ToolMessage(\n",
        "            content=f\"Tool error: Please check your input and try again. ({str(e)})\",\n",
        "            tool_call_id=request.tool_call[\"id\"]\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v38DHhGDqgOR"
      },
      "outputs": [],
      "source": [
        "playwright_agent = create_agent(\n",
        "    model=base_llm,\n",
        "    tools=creative_tools,\n",
        "    system_prompt=\"\"\"You are a poet and writer. Don't explain or ask, just produce the asked result.\n",
        "    When creating text that requires that words rhyme, use the tools to find rhyming words.\n",
        "    Also use the tool to insure rythmic validity of the poem.\n",
        "\n",
        "Use the provided tools to:\n",
        "- Find rhymes for poetic dialogue\n",
        "- Count syllables for rhythm\n",
        "- Analyze meter for dramatic effect\n",
        "\"\"\",\n",
        "    middleware=[handle_tool_errors]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEVsTeZwqtFO",
        "outputId": "9acb668b-1e47-4e6e-ec2b-bf69b1181507"
      },
      "outputs": [],
      "source": [
        "prompt = \"Write me a poem about AI discovering love, use the tools at your disposition\"\n",
        "\n",
        "result = playwright_agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": prompt}]}\n",
        ")\n",
        "\n",
        "script_text = result[\"messages\"][-1].content\n",
        "\n",
        "print(result)\n",
        "print(script_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VBYydDbt-pG"
      },
      "source": [
        "## Multi-agent system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zr-X9ebPuB48"
      },
      "outputs": [],
      "source": [
        "# idea generation\n",
        "idea_agent = create_agent(\n",
        "    model=base_llm,\n",
        "    tools=[],\n",
        "    system_prompt=SystemMessage(\n",
        "        content=(\n",
        "            \"You are a creative ideation assistant.\\n\"\n",
        "            \"Generate a strong, original concept for a creative text.\\n\"\n",
        "            \"Output only the idea, no prose.\"\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "\n",
        "# writing\n",
        "writer_agent = create_agent(\n",
        "    model=base_llm,\n",
        "    tools=[],\n",
        "    system_prompt=SystemMessage(\n",
        "        content=(\n",
        "            \"You are a creative writer.\\n\"\n",
        "            \"Write a complete creative text based on the provided idea.\\n\"\n",
        "            \"Output only the creative content.\"\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "\n",
        "# editing\n",
        "editor_agent = create_agent(\n",
        "    model=base_llm,\n",
        "    tools=[],\n",
        "    system_prompt=SystemMessage(\n",
        "        content=(\n",
        "            \"You are a literary editor.\\n\"\n",
        "            \"Improve style, flow, and emotional impact.\\n\"\n",
        "            \"Do not add commentary.\\n\"\n",
        "            \"Output only the revised creative text.\"\n",
        "        )\n",
        "    ),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtRUrDT8uSxC"
      },
      "outputs": [],
      "source": [
        "\n",
        "# orchestrating everything\n",
        "\n",
        "user_prompt = \"A short piece of speculative fiction about memory loss.\"\n",
        "\n",
        "# Step 1: generate idea\n",
        "idea_result = idea_agent.invoke({\n",
        "    \"messages\": [HumanMessage(content=user_prompt)]\n",
        "})\n",
        "idea = idea_result[\"messages\"][-1].content\n",
        "\n",
        "# Step 2: write draft\n",
        "draft_result = writer_agent.invoke({\n",
        "    \"messages\": [HumanMessage(content=idea)]\n",
        "})\n",
        "draft = draft_result[\"messages\"][-1].content\n",
        "\n",
        "# Step 3: edit draft\n",
        "final_result = editor_agent.invoke({\n",
        "    \"messages\": [HumanMessage(content=draft)]\n",
        "})\n",
        "\n",
        "final_text = final_result[\"messages\"][-1].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnzlLJuXu3EB"
      },
      "outputs": [],
      "source": [
        "final_text = final_result[\"messages\"][-1].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LqxHS6nuiON"
      },
      "outputs": [],
      "source": [
        "def print_block(title: str, content: str):\n",
        "    line = \"â•\" * 80\n",
        "    print(f\"\\n{line}\")\n",
        "    print(f\"{title}\")\n",
        "    print(line)\n",
        "    print(content.strip())\n",
        "    print(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GoZBoMUumVq",
        "outputId": "b18a806e-8b47-4058-c0ba-b2c10c28840c"
      },
      "outputs": [],
      "source": [
        "print_block(\n",
        "    \"USER PROMPT\",\n",
        "    user_prompt\n",
        ")\n",
        "\n",
        "print_block(\n",
        "    \"AGENT 1 â€” IDEA GENERATOR OUTPUT\",\n",
        "    idea\n",
        ")\n",
        "\n",
        "print_block(\n",
        "    \"AGENT 2 â€” WRITER DRAFT\",\n",
        "    draft\n",
        ")\n",
        "\n",
        "print_block(\n",
        "    \"AGENT 3 â€” EDITED FINAL TEXT\",\n",
        "    final_text\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjIgCIUWwiSp"
      },
      "source": [
        "## Improvements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfFZ8OhqwxFM"
      },
      "source": [
        "### User context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqNh-6c1wkTj"
      },
      "outputs": [],
      "source": [
        "from typing import TypedDict\n",
        "from langchain.agents import create_agent\n",
        "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
        "from langchain.messages import HumanMessage\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Context schema\n",
        "# -------------------------\n",
        "class Context(TypedDict):\n",
        "    user_role: str\n",
        "    user_name: str\n",
        "    include_user_in_story: bool\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Dynamic system prompt\n",
        "# -------------------------\n",
        "@dynamic_prompt\n",
        "def user_role_prompt(request: ModelRequest) -> str:\n",
        "    role = request.runtime.context.get(\"user_role\", \"user\")\n",
        "    name = request.runtime.context.get(\"user_name\", \"the user\")\n",
        "    include = request.runtime.context.get(\"include_user_in_story\", False)\n",
        "\n",
        "    base = \"You are a creative writing assistant.\"\n",
        "\n",
        "    if include:\n",
        "        base += f\" You may include {name} as a character if appropriate.\"\n",
        "\n",
        "    if role == \"expert\":\n",
        "        return base + \" Use rich language and experimental structure.\"\n",
        "    elif role == \"beginner\":\n",
        "        return base + \" Keep the language simple and accessible.\"\n",
        "\n",
        "    return base\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Agent\n",
        "# -------------------------\n",
        "creative_agent = create_agent(\n",
        "    model=base_llm,\n",
        "    tools=[],\n",
        "    middleware=[user_role_prompt],\n",
        "    context_schema=Context,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1StteBO2wnHT",
        "outputId": "65374398-88e5-43f9-c0d6-ee3ad0bd7d78"
      },
      "outputs": [],
      "source": [
        "def print_block(title, content):\n",
        "    line = \"â•\" * 80\n",
        "    print(f\"\\n{line}\")\n",
        "    print(title)\n",
        "    print(line)\n",
        "    print(content.strip())\n",
        "    print(line)\n",
        "\n",
        "\n",
        "user_prompt = \"Write a short speculative story about forgotten memories.\"\n",
        "\n",
        "print_block(\"ðŸ§  USER PROMPT\", user_prompt)\n",
        "\n",
        "result = creative_agent.invoke(\n",
        "    {\"messages\": [HumanMessage(content=user_prompt)]},\n",
        "    context={\n",
        "        \"user_role\": \"expert\",\n",
        "        \"user_name\": \"Paul\",\n",
        "        \"include_user_in_story\": True,\n",
        "    }\n",
        ")\n",
        "\n",
        "final_text = result[\"messages\"][-1].content\n",
        "print_block(\"âœï¸ SINGLE AGENT OUTPUT\", final_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYwJBuoqwy_K"
      },
      "source": [
        "### Human in the loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CJ6K3m0w0-0"
      },
      "outputs": [],
      "source": [
        "from langchain.agents.middleware import HumanInTheLoopMiddleware\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "from langchain.messages import HumanMessage\n",
        "\n",
        "\n",
        "@tool\n",
        "def validate(idea: str):\n",
        "  \"\"\"\n",
        "  Validate the idea with the user\n",
        "  \"\"\"\n",
        "  return\n",
        "\n",
        "idea_agent = create_agent(\n",
        "    model=base_llm,\n",
        "    tools=[validate],\n",
        "    system_prompt=(\n",
        "        \"You are an idea generator.\\n\"\n",
        "        \"Propose ONE strong creative idea in 2â€“3 sentences.\\n\"\n",
        "        \"No prose, no writing yet.\\n\"\n",
        "        \"You must get human approval before you move forward with the idea.\\n\"\n",
        "        \"Do this by invoking the validate tool\"\n",
        "    ),\n",
        "    middleware=[\n",
        "        HumanInTheLoopMiddleware(\n",
        "            interrupt_on={\n",
        "                \"validate\": True\n",
        "            }\n",
        "        )\n",
        "    ],\n",
        "    checkpointer=InMemorySaver(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgFQIXKUw3qm",
        "outputId": "78eeca38-3e6d-45da-c468-e42ee571bd09"
      },
      "outputs": [],
      "source": [
        "print_block(\"ðŸ’¡ IDEA GENERATION\", \"Generating idea, I want to first.\")\n",
        "\n",
        "config = {\"configurable\": {\"thread_id\": \"thread-1\"}}\n",
        "\n",
        "idea_result = idea_agent.invoke({\n",
        "    \"messages\": [HumanMessage(content=\"Generate a speculative fiction idea.\")]\n",
        "},config=config)\n",
        "\n",
        "print(idea_result)\n",
        "\n",
        "idea = idea_result[\"messages\"][-1].content\n",
        "print_block(\"ðŸ’¡ APPROVED IDEA\", idea)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsAG6UcnymoK"
      },
      "source": [
        "### Multi-agent (graph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U65ucXvmyoTI"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import tool\n",
        "\n",
        "\n",
        "idea_subagent = create_agent(\n",
        "    model=base_llm,\n",
        "    tools=[],\n",
        "    system_prompt=\"Generate a strong creative story idea.\"\n",
        ")\n",
        "\n",
        "writer_subagent = create_agent(\n",
        "    model=base_llm,\n",
        "    tools=[],\n",
        "    system_prompt=\"Write a complete creative text from the given idea.\"\n",
        ")\n",
        "\n",
        "editor_subagent = create_agent(\n",
        "    model=base_llm,\n",
        "    tools=[],\n",
        "    system_prompt=\"Edit the text for clarity, flow, and emotional impact.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDN08aNryo4I"
      },
      "outputs": [],
      "source": [
        "@tool(\"generate_idea\", description=\"Generate a creative story idea\")\n",
        "def generate_idea(prompt: str) -> str:\n",
        "    result = idea_subagent.invoke({\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "    })\n",
        "    return result[\"messages\"][-1].content\n",
        "\n",
        "\n",
        "@tool(\"write_story\", description=\"Write a story from an idea\")\n",
        "def write_story(idea: str) -> str:\n",
        "    result = writer_subagent.invoke({\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": idea}]\n",
        "    })\n",
        "    return result[\"messages\"][-1].content\n",
        "\n",
        "\n",
        "@tool(\"edit_story\", description=\"Edit and polish a story\")\n",
        "def edit_story(text: str) -> str:\n",
        "    result = editor_subagent.invoke({\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": text}]\n",
        "    })\n",
        "    return result[\"messages\"][-1].content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhhYYUN8ytRy"
      },
      "outputs": [],
      "source": [
        "supervisor = create_agent(\n",
        "    model=base_llm,\n",
        "    tools=[generate_idea, write_story, edit_story],\n",
        "    system_prompt=(\n",
        "        \"You are a supervisor coordinating creative subagents.\\n\"\n",
        "        \"Workflow:\\n\"\n",
        "        \"1. Generate idea\\n\"\n",
        "        \"2. Write story\\n\"\n",
        "        \"3. Edit story\\n\"\n",
        "        \"Return only the final edited text\\n\"\n",
        "        \" after generating the idea, then writing the story, and editing it\"\n",
        "    ),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGSb9RVOyvlb",
        "outputId": "d0d21509-0f4c-48dc-90c3-1e5bc9e77db1"
      },
      "outputs": [],
      "source": [
        "print_block(\"ðŸ§  USER PROMPT\", \"Write a short speculative story about memory loss.\")\n",
        "\n",
        "result = supervisor.invoke({\n",
        "    \"messages\": [{\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Write a short speculative story about memory loss.\"\n",
        "    }]\n",
        "})\n",
        "\n",
        "print(result)\n",
        "final_story = result[\"messages\"][-1].content\n",
        "print_block(\"ðŸ“– FINAL STORY\", final_story)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JriHn7gJzcbx"
      },
      "outputs": [],
      "source": [
        "\n",
        "def pretty_print_messages(messages):\n",
        "    print(\"=\"*80)\n",
        "    print(\"ðŸ’¬ Conversation Trace\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    for idx, msg in enumerate(messages, start=1):\n",
        "        if isinstance(msg, HumanMessage):\n",
        "            role = \"USER\"\n",
        "        elif isinstance(msg, AIMessage):\n",
        "            role = \"AI\"\n",
        "        elif isinstance(msg, ToolMessage):\n",
        "            role = f\"TOOL ({msg.name})\" if hasattr(msg, \"name\") else \"TOOL\"\n",
        "        else:\n",
        "            role = \"UNKNOWN\"\n",
        "\n",
        "        print(f\"\\n[{idx}] {role}\")\n",
        "        print(\"-\"*80)\n",
        "        # Content\n",
        "        content = getattr(msg, \"content\", \"\")\n",
        "        print(content.strip() if content else \"<No content>\")\n",
        "\n",
        "        # Additional info\n",
        "        if hasattr(msg, \"tool_call_id\") and msg.tool_call_id:\n",
        "            print(f\"\\nTool call id: {msg.tool_call_id}\")\n",
        "\n",
        "        if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
        "            print(f\"\\nTool calls:\")\n",
        "            for call in msg.tool_calls:\n",
        "                print(f\"   - {call['name']}({call['args']}) -> id={call['id']}\")\n",
        "\n",
        "        if hasattr(msg, \"response_metadata\") and msg.response_metadata:\n",
        "            model = msg.response_metadata.get(\"model_name\")\n",
        "            reason = msg.response_metadata.get(\"finish_reason\")\n",
        "            if model or reason:\n",
        "                print(f\"\\nModel metadata: {model}, finish_reason: {reason}\")\n",
        "        print(\"-\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGsA8w9TzdEa",
        "outputId": "8bab03ab-29ad-4f95-ebe7-c2bf4764c4aa"
      },
      "outputs": [],
      "source": [
        "pretty_print_messages(result[\"messages\"])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
